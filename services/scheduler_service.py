#!/usr/bin/env python3
"""
ä»»åŠ¡è°ƒåº¦æœåŠ¡
"""

from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.executors.pool import ThreadPoolExecutor
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore
from datetime import datetime, timedelta
from loguru import logger
from typing import Dict, Any

from config.config import config
from models.database import TaskSchedule

class SchedulerService:
    """ä»»åŠ¡è°ƒåº¦æœåŠ¡ç±»"""
    
    def __init__(self):
        # é…ç½®ä½œä¸šå­˜å‚¨
        jobstores = {
            'default': SQLAlchemyJobStore(url=config.database.uri)
        }
        
        # é…ç½®æ‰§è¡Œå™¨
        executors = {
            'default': ThreadPoolExecutor(max_workers=config.scheduler.max_workers)
        }
        
        # ä½œä¸šé»˜è®¤é…ç½®
        job_defaults = {
            'coalesce': True,  # åˆå¹¶å¤šä¸ªå¾…æ‰§è¡Œçš„åŒåä»»åŠ¡
            'max_instances': 1,  # åŒä¸€ä»»åŠ¡æœ€å¤šåŒæ—¶è¿è¡Œ1ä¸ªå®ä¾‹
            'misfire_grace_time': 30  # ä»»åŠ¡é”™è¿‡æ‰§è¡Œæ—¶é—´çš„å®½é™æœŸ
        }
        
        # åˆ›å»ºè°ƒåº¦å™¨
        self.scheduler = BackgroundScheduler(
            jobstores=jobstores,
            executors=executors,
            job_defaults=job_defaults,
            timezone=config.scheduler.timezone
        )
        
        self.is_running = False
    
    def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if not self.is_running:
            try:
                self.scheduler.start()
                self.is_running = True
                logger.info("ğŸ“… ä»»åŠ¡è°ƒåº¦å™¨å¯åŠ¨æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ è°ƒåº¦å™¨å¯åŠ¨å¤±è´¥: {e}")
                raise
    
    def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        if self.is_running:
            try:
                self.scheduler.shutdown(wait=True)
                self.is_running = False
                logger.info("ğŸ“… ä»»åŠ¡è°ƒåº¦å™¨å·²åœæ­¢")
            except Exception as e:
                logger.error(f"âŒ åœæ­¢è°ƒåº¦å™¨å¤±è´¥: {e}")
    
    def add_task(self, task: TaskSchedule):
        """æ·»åŠ ä»»åŠ¡åˆ°è°ƒåº¦å™¨"""
        try:
            # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©æ‰§è¡Œå‡½æ•°
            func = self._get_task_function(task.task_type)
            if not func:
                logger.error(f"âŒ æœªçŸ¥çš„ä»»åŠ¡ç±»å‹: {task.task_type}")
                return False
            
            # è§£æcronè¡¨è¾¾å¼
            cron_parts = task.cron_expression.split()
            if len(cron_parts) != 5:
                logger.error(f"âŒ æ— æ•ˆçš„cronè¡¨è¾¾å¼: {task.cron_expression}")
                return False
            
            minute, hour, day, month, day_of_week = cron_parts
            
            # åˆ›å»ºè§¦å‘å™¨
            trigger = CronTrigger(
                minute=minute,
                hour=hour,
                day=day,
                month=month,
                day_of_week=day_of_week,
                timezone=config.scheduler.timezone
            )
            
            # æ·»åŠ ä½œä¸š
            self.scheduler.add_job(
                func=func,
                trigger=trigger,
                id=f"task_{task.id}",
                name=task.name,
                args=[task.config_data],
                replace_existing=True,
                coalesce=True,
                max_instances=1
            )
            
            # æ›´æ–°æ•°æ®åº“ä¸­çš„ä¸‹æ¬¡è¿è¡Œæ—¶é—´
            next_run = self.scheduler.get_job(f"task_{task.id}").next_run_time
            task.next_run = next_run
            
            from models.database import db
            db.session.commit()
            
            logger.info(f"âœ… ä»»åŠ¡ '{task.name}' å·²æ·»åŠ åˆ°è°ƒåº¦å™¨ï¼Œä¸‹æ¬¡è¿è¡Œ: {next_run}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ ä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    def remove_task(self, task_id: int):
        """ç§»é™¤ä»»åŠ¡"""
        try:
            job_id = f"task_{task_id}"
            if self.scheduler.get_job(job_id):
                self.scheduler.remove_job(job_id)
                logger.info(f"âœ… ä»»åŠ¡ {job_id} å·²ç§»é™¤")
                return True
            else:
                logger.warning(f"âš ï¸ ä»»åŠ¡ {job_id} ä¸å­˜åœ¨")
                return False
        except Exception as e:
            logger.error(f"âŒ ç§»é™¤ä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    def get_jobs(self):
        """è·å–æ‰€æœ‰ä½œä¸šä¿¡æ¯"""
        jobs = []
        for job in self.scheduler.get_jobs():
            jobs.append({
                'id': job.id,
                'name': job.name,
                'next_run': job.next_run_time.isoformat() if job.next_run_time else None,
                'trigger': str(job.trigger)
            })
        return jobs
    
    def _get_task_function(self, task_type: str):
        """æ ¹æ®ä»»åŠ¡ç±»å‹è·å–æ‰§è¡Œå‡½æ•°"""
        task_functions = {
            'crawl_all': self._crawl_all_websites,
            'crawl_website': self._crawl_single_website,
            'data_cleanup': self._cleanup_old_data,
            'push_summary': self._push_daily_summary,
            'health_check': self._health_check
        }
        return task_functions.get(task_type)
    
    def _crawl_all_websites(self, config_data: Dict[str, Any]):
        """çˆ¬å–æ‰€æœ‰ç½‘ç«™ä»»åŠ¡"""
        try:
            logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œå®šæ—¶çˆ¬å–ä»»åŠ¡")
            
            # è¿™é‡Œéœ€è¦åœ¨åº”ç”¨ä¸Šä¸‹æ–‡ä¸­æ‰§è¡Œ
            from app import create_app
            app = create_app()
            
            with app.app_context():
                from services.crawler_service import CrawlerService
                crawler_service = CrawlerService()
                result = crawler_service.crawl_all_websites()
                
                logger.info(f"âœ… å®šæ—¶çˆ¬å–å®Œæˆ: {result}")
                
                # è®°å½•ä»»åŠ¡æ‰§è¡Œ
                self._log_task_execution('crawl_all', True, str(result))
                
        except Exception as e:
            logger.error(f"âŒ å®šæ—¶çˆ¬å–ä»»åŠ¡å¤±è´¥: {e}")
            self._log_task_execution('crawl_all', False, str(e))
    
    def _crawl_single_website(self, config_data: Dict[str, Any]):
        """çˆ¬å–å•ä¸ªç½‘ç«™ä»»åŠ¡"""
        try:
            website_id = config_data.get('website_id')
            if not website_id:
                logger.error("âŒ ç¼ºå°‘website_idå‚æ•°")
                return
            
            logger.info(f"ğŸš€ å¼€å§‹çˆ¬å–ç½‘ç«™ {website_id}")
            
            from app import create_app
            app = create_app()
            
            with app.app_context():
                from services.crawler_service import CrawlerService
                from models.database import WebsiteConfig, KeywordConfig
                
                website = WebsiteConfig.query.get(website_id)
                if not website:
                    logger.error(f"âŒ ç½‘ç«™ {website_id} ä¸å­˜åœ¨")
                    return
                
                keywords = KeywordConfig.query.filter_by(
                    website_id=website_id, is_active=True
                ).all()
                
                crawler_service = CrawlerService()
                result = crawler_service.crawl_website(website, keywords)
                
                logger.info(f"âœ… ç½‘ç«™çˆ¬å–å®Œæˆ: {result}")
                self._log_task_execution('crawl_website', True, str(result))
                
        except Exception as e:
            logger.error(f"âŒ ç½‘ç«™çˆ¬å–ä»»åŠ¡å¤±è´¥: {e}")
            self._log_task_execution('crawl_website', False, str(e))
    
    def _cleanup_old_data(self, config_data: Dict[str, Any]):
        """æ¸…ç†æ—§æ•°æ®ä»»åŠ¡"""
        try:
            days_to_keep = config_data.get('days_to_keep', 30)
            cutoff_date = datetime.now() - timedelta(days=days_to_keep)
            
            logger.info(f"ğŸ§¹ å¼€å§‹æ¸…ç† {days_to_keep} å¤©å‰çš„æ•°æ®")
            
            from app import create_app
            app = create_app()
            
            with app.app_context():
                from models.database import db, CrawledPost, SystemLog
                
                # æ¸…ç†æ—§å¸–å­
                old_posts = CrawledPost.query.filter(
                    CrawledPost.created_at < cutoff_date
                ).count()
                
                CrawledPost.query.filter(
                    CrawledPost.created_at < cutoff_date
                ).delete()
                
                # æ¸…ç†æ—§æ—¥å¿—
                old_logs = SystemLog.query.filter(
                    SystemLog.created_at < cutoff_date
                ).count()
                
                SystemLog.query.filter(
                    SystemLog.created_at < cutoff_date
                ).delete()
                
                db.session.commit()
                
                result = f"æ¸…ç†äº† {old_posts} æ¡å¸–å­å’Œ {old_logs} æ¡æ—¥å¿—"
                logger.info(f"âœ… æ•°æ®æ¸…ç†å®Œæˆ: {result}")
                self._log_task_execution('data_cleanup', True, result)
                
        except Exception as e:
            logger.error(f"âŒ æ•°æ®æ¸…ç†ä»»åŠ¡å¤±è´¥: {e}")
            self._log_task_execution('data_cleanup', False, str(e))
    
    def _push_daily_summary(self, config_data: Dict[str, Any]):
        """æ¨é€æ¯æ—¥æ±‡æ€»ä»»åŠ¡"""
        try:
            logger.info("ğŸ“Š å¼€å§‹ç”Ÿæˆæ¯æ—¥æ±‡æ€»")
            
            from app import create_app
            app = create_app()
            
            with app.app_context():
                from models.database import CrawledPost
                from services.feishu_service import FeishuService
                
                # è·å–ä»Šæ—¥æ•°æ®
                today_start = datetime.now().replace(hour=0, minute=0, second=0)
                today_posts = CrawledPost.query.filter(
                    CrawledPost.created_at >= today_start
                ).all()
                
                # ç”Ÿæˆæ±‡æ€»
                summary = self._generate_daily_summary(today_posts)
                
                # æ¨é€æ±‡æ€»
                feishu_service = FeishuService()
                success = feishu_service.send_daily_summary(summary)
                
                result = f"æ¨é€æ¯æ—¥æ±‡æ€»: {len(today_posts)} æ¡å¸–å­"
                logger.info(f"âœ… æ¯æ—¥æ±‡æ€»å®Œæˆ: {result}")
                self._log_task_execution('push_summary', success, result)
                
        except Exception as e:
            logger.error(f"âŒ æ¯æ—¥æ±‡æ€»ä»»åŠ¡å¤±è´¥: {e}")
            self._log_task_execution('push_summary', False, str(e))
    
    def _health_check(self, config_data: Dict[str, Any]):
        """ç³»ç»Ÿå¥åº·æ£€æŸ¥ä»»åŠ¡"""
        try:
            logger.info("ğŸ¥ å¼€å§‹ç³»ç»Ÿå¥åº·æ£€æŸ¥")
            
            # æ£€æŸ¥æ•°æ®åº“è¿æ¥
            # æ£€æŸ¥ç½‘ç»œè¿æ¥
            # æ£€æŸ¥ç£ç›˜ç©ºé—´ç­‰
            
            result = "ç³»ç»Ÿè¿è¡Œæ­£å¸¸"
            logger.info(f"âœ… å¥åº·æ£€æŸ¥å®Œæˆ: {result}")
            self._log_task_execution('health_check', True, result)
            
        except Exception as e:
            logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            self._log_task_execution('health_check', False, str(e))
    
    def _generate_daily_summary(self, posts):
        """ç”Ÿæˆæ¯æ—¥æ±‡æ€»"""
        if not posts:
            return {
                'title': 'ğŸ“Š ä»Šæ—¥æ•°æ®æ±‡æ€»',
                'content': 'ä»Šæ—¥æš‚æ— æ–°æ•°æ®',
                'total_posts': 0,
                'pushed_posts': 0,
                'top_keywords': []
            }
        
        # ç»Ÿè®¡æ•°æ®
        total_posts = len(posts)
        pushed_posts = len([p for p in posts if p.is_pushed])
        
        # ç»Ÿè®¡å…³é”®è¯
        keyword_count = {}
        for post in posts:
            if post.matched_keywords:
                for keyword in post.matched_keywords:
                    keyword_count[keyword] = keyword_count.get(keyword, 0) + 1
        
        top_keywords = sorted(keyword_count.items(), key=lambda x: x[1], reverse=True)[:5]
        
        return {
            'title': 'ğŸ“Š ä»Šæ—¥æ•°æ®æ±‡æ€»',
            'content': f'ä»Šæ—¥å…±çˆ¬å– {total_posts} æ¡å¸–å­ï¼Œæ¨é€ {pushed_posts} æ¡',
            'total_posts': total_posts,
            'pushed_posts': pushed_posts,
            'top_keywords': top_keywords
        }
    
    def _log_task_execution(self, task_type: str, success: bool, message: str):
        """è®°å½•ä»»åŠ¡æ‰§è¡Œæƒ…å†µ"""
        try:
            from app import create_app
            app = create_app()
            
            with app.app_context():
                from models.database import db, SystemLog
                
                log = SystemLog(
                    level='INFO' if success else 'ERROR',
                    module='scheduler_service',
                    message=f"ä»»åŠ¡æ‰§è¡Œ - {task_type}: {message}",
                    extra_data={
                        'task_type': task_type,
                        'success': success,
                        'timestamp': datetime.now().isoformat()
                    }
                )
                
                db.session.add(log)
                db.session.commit()
                
        except Exception as e:
            logger.error(f"âŒ è®°å½•ä»»åŠ¡æ—¥å¿—å¤±è´¥: {e}")

# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
scheduler_service = SchedulerService() 